{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "29d65a12",
   "metadata": {},
   "source": [
    "### Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "87a41a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103594, 23)\n",
      "(25893, 23)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Gender</th>\n",
       "      <th>Customer_Type</th>\n",
       "      <th>Age</th>\n",
       "      <th>Type_of_Travel</th>\n",
       "      <th>Class</th>\n",
       "      <th>Flight_Distance</th>\n",
       "      <th>Inflight_wifi_service</th>\n",
       "      <th>Departure_Arrival_time_convenient</th>\n",
       "      <th>Ease_of_Online_booking</th>\n",
       "      <th>Gate_location</th>\n",
       "      <th>Food_and_drink</th>\n",
       "      <th>Online_boarding</th>\n",
       "      <th>Seat_comfort</th>\n",
       "      <th>Inflight_entertainment</th>\n",
       "      <th>On_board_service</th>\n",
       "      <th>Leg_room_service</th>\n",
       "      <th>Baggage_handling</th>\n",
       "      <th>Checkin_service</th>\n",
       "      <th>Inflight_service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Departure_Delay_in_Minutes</th>\n",
       "      <th>Arrival_Delay_in_Minutes</th>\n",
       "      <th>satisfaction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>13</td>\n",
       "      <td>Personal Travel</td>\n",
       "      <td>Eco Plus</td>\n",
       "      <td>460</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>25</td>\n",
       "      <td>18.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Male</td>\n",
       "      <td>disloyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>235</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>26</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>1142</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Female</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>25</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>562</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>11</td>\n",
       "      <td>9.0000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Male</td>\n",
       "      <td>Loyal Customer</td>\n",
       "      <td>61</td>\n",
       "      <td>Business travel</td>\n",
       "      <td>Business</td>\n",
       "      <td>214</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Gender      Customer_Type  Age   Type_of_Travel     Class  Flight_Distance  \\\n",
       "0    Male     Loyal Customer   13  Personal Travel  Eco Plus              460   \n",
       "1    Male  disloyal Customer   25  Business travel  Business              235   \n",
       "2  Female     Loyal Customer   26  Business travel  Business             1142   \n",
       "3  Female     Loyal Customer   25  Business travel  Business              562   \n",
       "4    Male     Loyal Customer   61  Business travel  Business              214   \n",
       "\n",
       "   Inflight_wifi_service  Departure_Arrival_time_convenient  \\\n",
       "0                      3                                  4   \n",
       "1                      3                                  2   \n",
       "2                      2                                  2   \n",
       "3                      2                                  5   \n",
       "4                      3                                  3   \n",
       "\n",
       "   Ease_of_Online_booking  Gate_location  Food_and_drink  Online_boarding  \\\n",
       "0                       3              1               5                3   \n",
       "1                       3              3               1                3   \n",
       "2                       2              2               5                5   \n",
       "3                       5              5               2                2   \n",
       "4                       3              3               4                5   \n",
       "\n",
       "   Seat_comfort  Inflight_entertainment  On_board_service  Leg_room_service  \\\n",
       "0             5                       5                 4                 3   \n",
       "1             1                       1                 1                 5   \n",
       "2             5                       5                 4                 3   \n",
       "3             2                       2                 2                 5   \n",
       "4             5                       3                 3                 4   \n",
       "\n",
       "   Baggage_handling  Checkin_service  Inflight_service  Cleanliness  \\\n",
       "0                 4                4                 5            5   \n",
       "1                 3                1                 4            1   \n",
       "2                 4                4                 4            5   \n",
       "3                 3                1                 4            2   \n",
       "4                 4                3                 3            3   \n",
       "\n",
       "   Departure_Delay_in_Minutes  Arrival_Delay_in_Minutes  satisfaction  \n",
       "0                          25                   18.0000             0  \n",
       "1                           1                    6.0000             0  \n",
       "2                           0                    0.0000             1  \n",
       "3                          11                    9.0000             0  \n",
       "4                           0                    0.0000             1  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import StratifiedKFold, GridSearchCV, ParameterGrid\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier, StackingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import xgboost as xgb\n",
    "import itertools as it\n",
    "import time as time\n",
    "\n",
    "pd.set_option(\"display.max_rows\", None)\n",
    "pd.set_option(\"display.max_columns\", None)\n",
    "pd.set_option('display.float_format', lambda x: '%.4f' % x)\n",
    "\n",
    "train = pd.read_csv('train.csv', index_col = 0)\n",
    "test = pd.read_csv('test.csv', index_col = 0)\n",
    "\n",
    "def data_prep(df):\n",
    "    df[\"satisfaction\"] = df[\"satisfaction\"].map({'neutral or dissatisfied': 0, 'satisfied':1})\n",
    "    df = df.dropna()\n",
    "    df = df.drop(columns=[\"id\"])\n",
    "    print(df.shape)\n",
    "    df.columns = df.columns.str.replace(' ', '_')\n",
    "    df.columns = df.columns.str.replace('/', '_')\n",
    "    df.columns = df.columns.str.replace('-', '_')\n",
    "    df['Type_of_Travel'] = df['Type_of_Travel'].astype('string')\n",
    "    df['Class'] = df['Class'].astype('string')\n",
    "    df['Gender'] = df['Gender'].astype('string')\n",
    "    df['Customer_Type'] = df['Customer_Type'].astype('string')\n",
    "    return df\n",
    "\n",
    "train = data_prep(train)\n",
    "test = data_prep(test)\n",
    "\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2b78f017",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(103594, 28)\n",
      "(25893, 28)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Flight_Distance</th>\n",
       "      <th>Inflight_wifi_service</th>\n",
       "      <th>Departure_Arrival_time_convenient</th>\n",
       "      <th>Ease_of_Online_booking</th>\n",
       "      <th>Gate_location</th>\n",
       "      <th>Food_and_drink</th>\n",
       "      <th>Online_boarding</th>\n",
       "      <th>Seat_comfort</th>\n",
       "      <th>Inflight_entertainment</th>\n",
       "      <th>On_board_service</th>\n",
       "      <th>Leg_room_service</th>\n",
       "      <th>Baggage_handling</th>\n",
       "      <th>Checkin_service</th>\n",
       "      <th>Inflight_service</th>\n",
       "      <th>Cleanliness</th>\n",
       "      <th>Departure_Delay_in_Minutes</th>\n",
       "      <th>Arrival_Delay_in_Minutes</th>\n",
       "      <th>satisfaction</th>\n",
       "      <th>Gender_Female</th>\n",
       "      <th>Gender_Male</th>\n",
       "      <th>Customer_Type_Loyal Customer</th>\n",
       "      <th>Customer_Type_disloyal Customer</th>\n",
       "      <th>Type_of_Travel_Business travel</th>\n",
       "      <th>Type_of_Travel_Personal Travel</th>\n",
       "      <th>Class_Business</th>\n",
       "      <th>Class_Eco</th>\n",
       "      <th>Class_Eco Plus</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>160</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>50</td>\n",
       "      <td>44.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>36</td>\n",
       "      <td>2863</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20</td>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>44</td>\n",
       "      <td>3377</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>49</td>\n",
       "      <td>1182</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>20.0000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Flight_Distance  Inflight_wifi_service  \\\n",
       "0   52              160                      5   \n",
       "1   36             2863                      1   \n",
       "2   20              192                      2   \n",
       "3   44             3377                      0   \n",
       "4   49             1182                      2   \n",
       "\n",
       "   Departure_Arrival_time_convenient  Ease_of_Online_booking  Gate_location  \\\n",
       "0                                  4                       3              4   \n",
       "1                                  1                       3              1   \n",
       "2                                  0                       2              4   \n",
       "3                                  0                       0              2   \n",
       "4                                  3                       4              3   \n",
       "\n",
       "   Food_and_drink  Online_boarding  Seat_comfort  Inflight_entertainment  \\\n",
       "0               3                4             3                       5   \n",
       "1               5                4             5                       4   \n",
       "2               2                2             2                       2   \n",
       "3               3                4             4                       1   \n",
       "4               4                1             2                       2   \n",
       "\n",
       "   On_board_service  Leg_room_service  Baggage_handling  Checkin_service  \\\n",
       "0                 5                 5                 5                2   \n",
       "1                 4                 4                 4                3   \n",
       "2                 4                 1                 3                2   \n",
       "3                 1                 1                 1                3   \n",
       "4                 2                 2                 2                4   \n",
       "\n",
       "   Inflight_service  Cleanliness  Departure_Delay_in_Minutes  \\\n",
       "0                 5            5                          50   \n",
       "1                 4            5                           0   \n",
       "2                 2            2                           0   \n",
       "3                 1            4                           0   \n",
       "4                 2            4                           0   \n",
       "\n",
       "   Arrival_Delay_in_Minutes  satisfaction  Gender_Female  Gender_Male  \\\n",
       "0                   44.0000             1              1            0   \n",
       "1                    0.0000             1              1            0   \n",
       "2                    0.0000             0              0            1   \n",
       "3                    6.0000             1              0            1   \n",
       "4                   20.0000             1              1            0   \n",
       "\n",
       "   Customer_Type_Loyal Customer  Customer_Type_disloyal Customer  \\\n",
       "0                             1                                0   \n",
       "1                             1                                0   \n",
       "2                             0                                1   \n",
       "3                             1                                0   \n",
       "4                             1                                0   \n",
       "\n",
       "   Type_of_Travel_Business travel  Type_of_Travel_Personal Travel  \\\n",
       "0                               1                               0   \n",
       "1                               1                               0   \n",
       "2                               1                               0   \n",
       "3                               1                               0   \n",
       "4                               1                               0   \n",
       "\n",
       "   Class_Business  Class_Eco  Class_Eco Plus  \n",
       "0               0          1               0  \n",
       "1               1          0               0  \n",
       "2               0          1               0  \n",
       "3               1          0               0  \n",
       "4               0          1               0  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categorical_columns = list(train.select_dtypes('string').columns)\n",
    "train = pd.get_dummies(train, columns = categorical_columns, drop_first = False)\n",
    "test = pd.get_dummies(test, columns = categorical_columns, drop_first = False)\n",
    "\n",
    "train = train.dropna()\n",
    "test = test.dropna()\n",
    "\n",
    "print(train.shape)\n",
    "print(test.shape)\n",
    "\n",
    "X = train.drop(columns=[\"satisfaction\"])\n",
    "y = train[\"satisfaction\"]\n",
    "Xtest = test.drop(columns=[\"satisfaction\"])\n",
    "ytest = test[\"satisfaction\"]\n",
    "\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d88f4f",
   "metadata": {},
   "source": [
    "### a) Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d59cd72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def confusion_matrix_data(pred_values, actual_values, cutoff=0.5):\n",
    "    bins=np.array([0,cutoff,1])\n",
    "    cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n",
    "    precision = 100*(cm[1,1])/(cm[0,1]+cm[1,1])\n",
    "    return precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5022f121",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc(pred_values, actual_values, cutoff=0.5):\n",
    "    bins=np.array([0,cutoff,1])\n",
    "    cm = np.histogram2d(actual_values, pred_values, bins=bins)[0]\n",
    "    accuracy = 100*(cm[0,0]+cm[1,1])/cm.sum()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "73447c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(125, 5, 6, 1) 97.28348450665317\n"
     ]
    }
   ],
   "source": [
    "oob_precision = {}\n",
    "for i in [75, 100, 125]:\n",
    "    for j in [1, 2, 3, 4, 5]:\n",
    "        for k in [2, 3, 4, 5, 6]:\n",
    "            for l in [1, 2, 3]:\n",
    "                model = RandomForestClassifier(n_estimators = i, max_features = j, min_samples_split = k, min_samples_leaf = l, n_jobs=-1, random_state=1, oob_score=True).fit(X, y)\n",
    "                oob_precision[i, j, k, l] = confusion_matrix_data(pd.Series(model.oob_decision_function_[:,1]), y)\n",
    "\n",
    "print(max(oob_precision, key=oob_precision.get), oob_precision[max(oob_precision, key=oob_precision.get)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "382cd79a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest model -- Precision on test data: 97.16485507246377\n",
      "Random forest model -- Accuracy on test data: 96.32719267755765\n"
     ]
    }
   ],
   "source": [
    "params = max(oob_precision, key=oob_precision.get)\n",
    "rf_params = {'n_estimators': params[0], 'max_features': params[1], 'min_samples_split': params[2], 'min_samples_leaf': params[3]}\n",
    "m1 = RandomForestClassifier(**rf_params, n_jobs=-1, random_state=1, oob_score=True)\n",
    "model = m1.fit(X, y)\n",
    "pred = model.predict_proba(Xtest)[:, 1]\n",
    "print(f\"Random forest model -- Precision on test data: {confusion_matrix_data(pred, ytest)}\")\n",
    "print(f\"Random forest model -- Accuracy on test data: {acc(pred, ytest)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b72e19",
   "metadata": {},
   "source": [
    "### b) AdaBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6ab4b328",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n",
      "Best: 0.969326 using {'base_estimator': DecisionTreeClassifier(max_depth=4), 'learning_rate': 0.1, 'n_estimators': 500}\n"
     ]
    }
   ],
   "source": [
    "model = AdaBoostClassifier(random_state = 1)\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [10, 50, 100,200,500]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01,0.1, 1.0]\n",
    "grid['base_estimator'] = [DecisionTreeClassifier(max_depth=1),DecisionTreeClassifier(max_depth=2),\n",
    "                          DecisionTreeClassifier(max_depth=3),DecisionTreeClassifier(max_depth=4)]\n",
    "# define the evaluation procedure\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, verbose=1, scoring='precision', refit='precision')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a79b080c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoost model -- Precision on test data: 96.9179320318149\n",
      "AdaBoost model -- Accuracy on test data: 96.20360715251226\n"
     ]
    }
   ],
   "source": [
    "params = grid_result.best_params_\n",
    "m2 = AdaBoostClassifier(**params, random_state=1)\n",
    "model = m2.fit(X,y)\n",
    "pred = model.predict_proba(Xtest)[:, 1]\n",
    "print(f\"AdaBoost model -- Precision on test data: {confusion_matrix_data(pred, ytest)}\")\n",
    "print(f\"AdaBoost model -- Accuracy on test data: {acc(pred, ytest)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3233030",
   "metadata": {},
   "source": [
    "### c) Gradient Boost "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "714049d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 128 candidates, totalling 384 fits\n",
      "Best: 0.971683 using {'learning_rate': 0.1, 'max_depth': 5, 'n_estimators': 200, 'subsample': 1.0}\n"
     ]
    }
   ],
   "source": [
    "model = GradientBoostingClassifier(random_state=1)\n",
    "grid = dict()\n",
    "grid['n_estimators'] = [50, 100,200,500]\n",
    "grid['learning_rate'] = [0.0001, 0.001, 0.01,0.1]\n",
    "grid['max_depth'] = [2,3,4,5]\n",
    "grid['subsample'] = [0.5,1.0]\n",
    "# define the evaluation procedure\n",
    "cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# define the grid search procedure\n",
    "grid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, verbose=1, scoring='precision', refit='precision')\n",
    "# execute the grid search\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize the best score and configuration\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "334196ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gradient Boost model -- Precision on test data: 97.07401032702238\n",
      "Gradient Boost model -- Accuracy on test data: 96.2460896767466\n"
     ]
    }
   ],
   "source": [
    "params = grid_result.best_params_\n",
    "m3 = GradientBoostingClassifier(**params,random_state=1)\n",
    "model = m3.fit(X,y)\n",
    "pred = model.predict_proba(Xtest)[:, 1]\n",
    "print(f\"Gradient Boost model -- Precision on test data: {confusion_matrix_data(pred, ytest)}\")\n",
    "print(f\"Gradient Boost model -- Accuracy on test data: {acc(pred, ytest)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d69341a",
   "metadata": {},
   "source": [
    "### d) XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b1e169fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 729 candidates, totalling 2187 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVILA\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:35:36] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Best: 0.966689 using {'gamma': 0.25, 'learning_rate': 0.1, 'max_depth': 8, 'n_estimators': 500, 'reg_lambda': 0, 'scale_pos_weight': 1.25}\n"
     ]
    }
   ],
   "source": [
    "param_grid = {'n_estimators':[25,100,500],\n",
    "              'max_depth': [6,7,8],\n",
    "              'learning_rate': [0.001,0.1,0.2],\n",
    "              'gamma': [0.1,0.25,0.5],\n",
    "              'reg_lambda':[0,0.01,0.001],\n",
    "              'scale_pos_weight':[1.25,1.5,1.75]}\n",
    "cv = StratifiedKFold(n_splits=3,shuffle=True,random_state=1)\n",
    "grid_search = GridSearchCV(estimator=xgb.XGBClassifier(random_state=1),\n",
    "                              param_grid = param_grid,verbose = 1,n_jobs=-1,cv = cv, scoring='precision', refit='precision')\n",
    "grid_result = grid_search.fit(X,y)\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db955f3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:36:03] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "XGBoost model -- Precision on test data: 96.71513193322563\n",
      "XGBoost model -- Accuracy on test data: 96.31174448692697\n"
     ]
    }
   ],
   "source": [
    "params = grid_result.best_params_\n",
    "m4 = xgb.XGBClassifier(**params,random_state=1)\n",
    "model = m4.fit(X,y)\n",
    "pred = model.predict_proba(Xtest)[:, 1]\n",
    "print(f\"XGBoost model -- Precision on test data: {confusion_matrix_data(pred, ytest)}\")\n",
    "print(f\"XGBoost model -- Accuracy on test data: {acc(pred, ytest)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07906cee",
   "metadata": {},
   "source": [
    "### 1) Voting ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4431a35e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVILA\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[03:39:23] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "predict_proba is not available when voting='hard'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_54420/948261589.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0men1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mVotingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimators\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'rf'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'ada'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'gb'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm3\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m'xgb'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mm4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvoting\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'hard'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0men1\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict_proba\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mXtest\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Voting ensemble model (hard) -- Precision on test data: {confusion_matrix_data(pred, ytest)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf\"Voting ensemble model (hard) -- Accuracy on test data: {acc(pred, ytest)}\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\ensemble\\_voting.py\u001b[0m in \u001b[0;36mpredict_proba\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    346\u001b[0m         \"\"\"\n\u001b[0;32m    347\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvoting\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'hard'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 348\u001b[1;33m             raise AttributeError(\"predict_proba is not available when\"\n\u001b[0m\u001b[0;32m    349\u001b[0m                                  \" voting=%r\" % self.voting)\n\u001b[0;32m    350\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_predict_proba\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: predict_proba is not available when voting='hard'"
     ]
    }
   ],
   "source": [
    "en1 = VotingClassifier(estimators = [('rf',m1), ('ada',m2), ('gb',m3), ('xgb',m4)], voting = 'hard')\n",
    "model = en1.fit(X,y)\n",
    "pred = model.predict_proba(Xtest)[:, 1]\n",
    "print(f\"Voting ensemble model (hard) -- Precision on test data: {confusion_matrix_data(pred, ytest)}\")\n",
    "print(f\"Voting ensemble model (hard) -- Accuracy on test data: {acc(pred, ytest)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "559e0699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVILA\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[12:39:59] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Voting ensemble model (soft) -- Precision on test data: 97.31124388919066\n",
      "Voting ensemble model (soft) -- Accuracy on test data: 96.47395048854902\n"
     ]
    }
   ],
   "source": [
    "en2 = VotingClassifier(estimators = [('rf',m1), ('ada',m2), ('gb',m3), ('xgb',m4)], voting = 'soft')\n",
    "model = en2.fit(X,y)\n",
    "pred = model.predict_proba(Xtest)[:, 1]\n",
    "print(f\"Voting ensemble model (soft) -- Precision on test data: {confusion_matrix_data(pred, ytest)}\")\n",
    "print(f\"Voting ensemble model (soft) -- Accuracy on test data: {acc(pred, ytest)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c78beee",
   "metadata": {},
   "source": [
    "### 2) Stacking ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3b72d15a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking ensemble model (LogisticRegression) -- Precision on test data: 97.09779179810725\n",
      "Stacking ensemble model (LogisticRegression) -- Accuracy on test data: 96.47008844089136\n"
     ]
    }
   ],
   "source": [
    "en3 = StackingClassifier(estimators = [('rf',m1), ('ada',m2), ('gb',m3), ('xgb',m4)],\n",
    "                        final_estimator=LogisticRegression(random_state=1,max_iter=10000),n_jobs=-1,\n",
    "                        cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1))\n",
    "model = en3.fit(X,y)\n",
    "pred = model.predict_proba(Xtest)[:, 1]\n",
    "print(f\"Stacking ensemble model (LogisticRegression) -- Precision on test data: {confusion_matrix_data(pred, ytest)}\")\n",
    "print(f\"Stacking ensemble model (LogisticRegression) -- Accuracy on test data: {acc(pred, ytest)}\")\n",
    "\n",
    "coefs = model.final_estimator_.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "30895af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stacking ensemble model (RandomForestClassifier) -- Precision on test data: 97.22549641853296\n",
      "Stacking ensemble model (RandomForestClassifier) -- Accuracy on test data: 96.33877882053065\n"
     ]
    }
   ],
   "source": [
    "en4 = StackingClassifier(estimators = [('rf',m1), ('ada',m2), ('gb',m3), ('xgb',m4)],\n",
    "                           final_estimator=RandomForestClassifier(n_estimators=500, max_features=1,random_state=1,oob_score=True),\n",
    "                           n_jobs=-1,cv = StratifiedKFold(n_splits=5,shuffle=True,random_state=1))\n",
    "model = en4.fit(X,y)\n",
    "pred = model.predict_proba(Xtest)[:, 1]\n",
    "print(f\"Stacking ensemble model (RandomForestClassifier) -- Precision on test data: {confusion_matrix_data(pred, ytest)}\")\n",
    "print(f\"Stacking ensemble model (RandomForestClassifier) -- Accuracy on test data: {acc(pred, ytest)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d8f9cb2",
   "metadata": {},
   "source": [
    "### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "9695c7b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models in order of importance:\n",
      "--------------------------------------------------\n",
      "#1: AdaBoost (22.482328547522403)\n",
      "#2: Random forest (4.381044277331529)\n",
      "#3: XGBoost (1.5488381852997994)\n",
      "#4: Gradient Boost (1.1774755007465192)\n"
     ]
    }
   ],
   "source": [
    "models = ['Random forest', 'AdaBoost', 'Gradient Boost', 'XGBoost']\n",
    "importances = dict(zip(models, list(coefs[0])))\n",
    "def importance(val):\n",
    "    return importances[val]\n",
    "\n",
    "ordered = sorted(importances, key = importance, reverse = True)\n",
    "\n",
    "print(\"Models in order of importance:\")\n",
    "print(\"-\"*50)\n",
    "for i, model in enumerate(ordered):\n",
    "    print(f\"#{i+1}: {model} ({importances[model]})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03287955",
   "metadata": {},
   "source": [
    "### Cutoffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "8173d23b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_cutoff(model):   \n",
    "    prec = {}\n",
    "    for i in (np.array(range(25, 1000, 25)) * 0.001):\n",
    "        pred = model.predict_proba(Xtest)[:, 1]\n",
    "        prec[i] = confusion_matrix_data(pred, ytest, cutoff=i)\n",
    "    best_prec = max(prec, key=prec.get)\n",
    "    print(best_prec, prec[best_prec])\n",
    "    print(f\"Precision : {confusion_matrix_data(pred, ytest, cutoff = best_prec)}\")\n",
    "    print(f\"Accuracy: {acc(pred, ytest, cutoff = best_prec)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "1b0985c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVILA\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:10:09] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "f1 = m1.fit(X,y) #rf\n",
    "f2 = m2.fit(X,y) #ada\n",
    "f3 = m3.fit(X,y) #gb\n",
    "f4 = m4.fit(X,y) #xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "96928964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.975 99.9870214146658\n",
      "Precision : 99.9870214146658\n",
      "Accuracy: 85.85718147761943\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVILA\\AppData\\Local\\Temp/ipykernel_54420/1039990700.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = 100*(cm[1,1])/(cm[0,1]+cm[1,1])\n",
      "C:\\Users\\AVILA\\AppData\\Local\\Temp/ipykernel_54420/1039990700.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = 100*(cm[1,1])/(cm[0,1]+cm[1,1])\n",
      "C:\\Users\\AVILA\\AppData\\Local\\Temp/ipykernel_54420/1039990700.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = 100*(cm[1,1])/(cm[0,1]+cm[1,1])\n",
      "C:\\Users\\AVILA\\AppData\\Local\\Temp/ipykernel_54420/1039990700.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = 100*(cm[1,1])/(cm[0,1]+cm[1,1])\n",
      "C:\\Users\\AVILA\\AppData\\Local\\Temp/ipykernel_54420/1039990700.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = 100*(cm[1,1])/(cm[0,1]+cm[1,1])\n",
      "C:\\Users\\AVILA\\AppData\\Local\\Temp/ipykernel_54420/1039990700.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = 100*(cm[1,1])/(cm[0,1]+cm[1,1])\n",
      "C:\\Users\\AVILA\\AppData\\Local\\Temp/ipykernel_54420/1039990700.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = 100*(cm[1,1])/(cm[0,1]+cm[1,1])\n",
      "C:\\Users\\AVILA\\AppData\\Local\\Temp/ipykernel_54420/1039990700.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = 100*(cm[1,1])/(cm[0,1]+cm[1,1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.65 100.0\n",
      "Precision : 100.0\n",
      "Accuracy: 62.2446220986367\n",
      "0.975 99.94522348816827\n",
      "Precision : 99.94522348816827\n",
      "Accuracy: 91.3219789132198\n",
      "0.975 99.91050119331742\n",
      "Precision : 99.91050119331742\n",
      "Accuracy: 94.87506275827444\n"
     ]
    }
   ],
   "source": [
    "for model in [f1, f2, f3, f4]:\n",
    "    estimate_cutoff(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "d63217cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVILA\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:16:58] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVILA\\AppData\\Local\\Temp/ipykernel_54420/1039990700.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = 100*(cm[1,1])/(cm[0,1]+cm[1,1])\n",
      "C:\\Users\\AVILA\\AppData\\Local\\Temp/ipykernel_54420/1039990700.py:4: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  precision = 100*(cm[1,1])/(cm[0,1]+cm[1,1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9 100.0\n",
      "Precision : 100.0\n",
      "Accuracy: 69.20789402541227\n",
      "0.975 99.95901639344262\n",
      "Precision : 99.95901639344262\n",
      "Accuracy: 93.77051712818137\n",
      "0.975 99.89042733339974\n",
      "Precision : 99.89042733339974\n",
      "Accuracy: 94.79395975746341\n"
     ]
    }
   ],
   "source": [
    "#estimate_cutoff(en1.fit(X,y))\n",
    "estimate_cutoff(en2.fit(X,y))\n",
    "estimate_cutoff(en3.fit(X,y))\n",
    "estimate_cutoff(en4.fit(X,y))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e062b261",
   "metadata": {},
   "source": [
    "### Saving Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "a1f0e52f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "def save_model(model, filename):\n",
    "    # save the model to disk\n",
    "    filename = f'{filename}.sav'\n",
    "    pickle.dump(model, open(filename, 'wb'))\n",
    "    \n",
    "save_model(f1, 'f1')\n",
    "save_model(f2, 'f2')\n",
    "save_model(f3, 'f3')\n",
    "save_model(f4, 'f4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "0bfbd72e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AVILA\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13:57:57] WARNING: D:\\bld\\xgboost-split_1645118015404\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    }
   ],
   "source": [
    "ensemble1 = en2.fit(X,y) #soft voting\n",
    "ensemble2 = en3.fit(X,y) #logistic stacking\n",
    "ensemble3 = en4.fit(X,y) #RF stacking\n",
    "# We do not use hard voting ensemble, as it is not possible to search cutoffs when results must be 0 or 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "127b0b90",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(ensemble1, 'ensemble1')\n",
    "save_model(ensemble2, 'ensemble2')\n",
    "save_model(ensemble3, 'ensemble3')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05ad3692",
   "metadata": {},
   "source": [
    "### Feature Importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4a6e8f64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00617663, 0.00343445, 0.14233801, 0.00545094, 0.00691719,\n",
       "       0.0122112 , 0.00392513, 0.38385156, 0.01253875, 0.03345801,\n",
       "       0.01188793, 0.01144078, 0.01239789, 0.01754906, 0.01168233,\n",
       "       0.01364641, 0.00292074, 0.00431291, 0.00284916, 0.        ,\n",
       "       0.0610305 , 0.        , 0.1696069 , 0.        , 0.06349049,\n",
       "       0.00360832, 0.00327466], dtype=float32)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def load_model(filename):\n",
    "    # load the model from disk\n",
    "    loaded_model = pickle.load(open(f'{filename}.sav', 'rb'))\n",
    "    return loaded_model\n",
    "\n",
    "# 2nd to worst performance in terms of precision (even though less than 0.1% from 100%), best performance in terms of accuracy:\n",
    "loaded_model = load_model('f4')\n",
    "loaded_model.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "c5ea9056",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Online_boarding': 0.383852,\n",
       " 'Type_of_Travel_Business travel': 0.169607,\n",
       " 'Inflight_wifi_service': 0.142338,\n",
       " 'Class_Business': 0.06349,\n",
       " 'Customer_Type_Loyal Customer': 0.061031,\n",
       " 'Inflight_entertainment': 0.033458,\n",
       " 'Checkin_service': 0.017549,\n",
       " 'Cleanliness': 0.013646,\n",
       " 'Seat_comfort': 0.012539,\n",
       " 'Baggage_handling': 0.012398,\n",
       " 'Gate_location': 0.012211,\n",
       " 'On_board_service': 0.011888,\n",
       " 'Inflight_service': 0.011682,\n",
       " 'Leg_room_service': 0.011441,\n",
       " 'Ease_of_Online_booking': 0.006917,\n",
       " 'Age': 0.006177,\n",
       " 'Departure_Arrival_time_convenient': 0.005451,\n",
       " 'Arrival_Delay_in_Minutes': 0.004313,\n",
       " 'Food_and_drink': 0.003925,\n",
       " 'Class_Eco': 0.003608,\n",
       " 'Flight_Distance': 0.003434,\n",
       " 'Class_Eco Plus': 0.003275,\n",
       " 'Departure_Delay_in_Minutes': 0.002921,\n",
       " 'Gender_Female': 0.002849,\n",
       " 'Gender_Male': 0.0,\n",
       " 'Customer_Type_disloyal Customer': 0.0,\n",
       " 'Type_of_Travel_Personal Travel': 0.0}"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_features = list(loaded_model.feature_importances_)\n",
    "features = [round(feature, 6) for feature in loaded_features]\n",
    "feature_zip = zip(X.columns, features)\n",
    "feature_dict = {x: y for (x, y) in list(feature_zip)}\n",
    "sorted_dict = {k: v for k, v in sorted(feature_dict.items(), key=lambda item: item[1], reverse = True)}\n",
    "sorted_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb471aa",
   "metadata": {},
   "source": [
    "Some of the takeaways were foreseen. For example, gender is not that important."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "999d5da7",
   "metadata": {},
   "source": [
    "### Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "565244f2",
   "metadata": {},
   "source": [
    "**In order of precision:**\n",
    "\n",
    "Soft Voting <br>\n",
    "Cutoff: 0.9 <br>\n",
    "Precision : 100.0 <br>\n",
    "Accuracy: 69.20789402541227 <br>\n",
    "\n",
    "AdaBoost <br>\n",
    "Cutoff: 0.65 <br>\n",
    "Precision : 100.0 <br>\n",
    "Accuracy: 62.2446220986367 <br>\n",
    "\n",
    "Random Forest <br>\n",
    "Cutoff: 0.975 <br>\n",
    "Precision : 99.9870214146658 <br>\n",
    "Accuracy: 85.85718147761943 <br>\n",
    "\n",
    "Logistic Stacking <br>\n",
    "Cutoff: 0.975 <br>\n",
    "Precision : 99.95901639344262 <br>\n",
    "Accuracy: 93.77051712818137 <br>\n",
    "\n",
    "GradientBoost <br>\n",
    "Cutoff: 0.975 <br>\n",
    "Precision : 99.94522348816827 <br>\n",
    "Accuracy: 91.3219789132198 <br>\n",
    "\n",
    "XGBoost <br>\n",
    "Cutoff: 0.975 <br>\n",
    "Precision : 99.91050119331742 <br>\n",
    "Accuracy: 94.87506275827444 <br>\n",
    "\n",
    "Random Forest Stacking <br>\n",
    "Cutoff: 0.975 <br>\n",
    "Precision : 99.89042733339974 <br>\n",
    "Accuracy: 94.79395975746341 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8da111",
   "metadata": {},
   "source": [
    "**In order of accuracy:**\n",
    "\n",
    "XGBoost <br>\n",
    "Cutoff: 0.975 <br>\n",
    "Precision : 99.91050119331742 <br>\n",
    "Accuracy: 94.87506275827444 <br>\n",
    "\n",
    "Random Forest Stacking <br>\n",
    "Cutoff: 0.975 <br>\n",
    "Precision : 99.89042733339974 <br>\n",
    "Accuracy: 94.79395975746341 <br>\n",
    "\n",
    "Logistic Stacking <br>\n",
    "Cutoff: 0.975 <br>\n",
    "Precision : 99.95901639344262 <br>\n",
    "Accuracy: 93.77051712818137 <br>\n",
    "\n",
    "GradientBoost <br>\n",
    "Cutoff: 0.975 <br>\n",
    "Precision : 99.94522348816827 <br>\n",
    "Accuracy: 91.3219789132198 <br>\n",
    "\n",
    "Random Forest <br>\n",
    "Cutoff: 0.975 <br>\n",
    "Precision : 99.9870214146658 <br>\n",
    "Accuracy: 85.85718147761943 <br>\n",
    "\n",
    "Soft Voting <br>\n",
    "Cutoff: 0.9 <br>\n",
    "Precision : 100.0 <br>\n",
    "Accuracy: 69.20789402541227 <br>\n",
    "\n",
    "AdaBoost <br>\n",
    "Cutoff: 0.65 <br>\n",
    "Precision : 100.0 <br>\n",
    "Accuracy: 62.2446220986367 <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e555b336",
   "metadata": {},
   "source": [
    "#### As you can see, precision is \"inversely optimal\" to accuracy."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
